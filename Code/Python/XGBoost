### xgboost 모듈과 위스콘신 유방암 데이터 세트 로드


import xgboost as xgb
from xgboost import plot_importance
import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')


dataset = load_breast_cancer()
X_features = dataset.data
y_label = dataset.target


cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)
cancer_df['target'] = y_label
cancer_df.head(3)



### 전체 데이터 중 80% 는 학습용 뎅터, 20% 는 테스트용 데이터 추출        p235

X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size = 0.2, random_state = 156)

print(X_train.shape, X_test.shape)


dtrain = xgb.DMatrix(data = X_train, label = y_train)
dtest = xgb.DMatrix(data = X_test, label = y_test)



params = {'max_depth' : 3,
          'eta' : 0.1,
          'objective' : 'binary:logistic',
          'eval_metric':'logloss',
          'early_stoppings':100
    
}

num_rounds = 400



# train 데이터 세트는 'train', evaluation(test) 데이터 세트는 'eval'로 명기함

wlist = [(dtrain, 'train'), (dtest, 'eval')]


# 하이퍼 파라미터와 early stopping 파라미터를 train() 함수의 파라미터로 전달(최소 반복 횟수는 100으로 설정)

xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, early_stopping_rounds = 100, evals = wlist)




pred_probs = xgb_model.predict(dtest)
print('predict() 수행 결과값을 10개만 표시, 예측 확률값으로 표시됨')
print(np.round(pred_probs[:10], 3))


# 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측값 결정해 리스트 객체인 preds에 저장

preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]
print('예측값 10개만 표시 :', preds[:10])



# 테스트 실제 레이블 값을 가지는 y_test와 예측 레이블인 preds를 인자로 입력

from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score

def get_clf_eval(y_test, pred = None, pred_proba = None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    
    # ROC - AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    
    # ROC - AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'
          .format(accuracy, precision, recall, f1, roc_auc))

    
get_clf_eval(y_test, preds, pred_probs)



# xgboost의 plot_importance() API : 피처의 중요도를 막대그래프 형식으로 나타냄
# => 기본 평가 지표로 f1 스코어를 기반으로 해 각 피처의 중요도로를 나타냄


from xgboost import plot_importance
import matplotlib.pyplot as plt
%matplotlib inline


fig, ax = plt.subplots(figsize = (10, 12))
plot_importance(xgb_model, ax = ax)








from xgboost import XGBClassifier

xgb_wrapper = XGBClassifier(n_estimators = 400, learning_rate = 0.1, max_depth = 3)
xgb_wrapper.fit(X_train, y_train)
w_preds = xgb_wrapper.predict(X_test)
w_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, w_preds, w_pred_proba)



# plot_importance() API에 사이킷런 래퍼 클래스를 입력해도 파이썬 래퍼 클래스를 입력한 결과와 똑같이 시각화 결과를 도출해 줌

from xgboost import plot_importance
import matplotlib.pyplot as plt
%matplotlib inline

fig, ax = plt.subplots(figsize = (10, 12))


# 사이킷런 Wrapper 클래스를 입력해도 무방

plot_importance(xgb_wrapper, ax = ax)
