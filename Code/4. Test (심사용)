##### Package Load #####

  from main import *
  from sklearn.model_selection import GridSearchcy
  from torch.utils.data import DataLoader, TensorDataset
  from sklearn.metrics import roc_auc_score
  from sklearn.metrics import mean_squared_error
  from sklearn.preprocessing import MinMaxScaler
  from contral_seed import seed_everything
  import torch
  import torch.nn.functional as F

  from torch import пn.optim
  import matplotlib.pyplot as plt

  from mpl_toolkits.mplot3d import Axes3D     # 생성되는 이미지를 관찰하기 위함. 3차원 플롯
  from mathplotlib import cm                  # 데이터 포인트에 색상을 입히는 것에 사용됨
  from torch.utils.data import DataLoader. TensorDataset
  import joblib
  import pickle

  np.set_printoptions(suppress=True, precision = 5)



##### 저장된 주요 변수 불러오기 #####

  var_set = {'AGE_KCB', 'BS_YR_0', 'CNT', 'SEX', 'car_own_tp_1_sum', 'car_own_tp_7_sum', 'car_own_tp_8_sum', 'car_size_1_sum', 'car_size_2_sum',
            'car_size_3_sum', 'car_size_4_sum', 'car_size_5_sum', 'home_sigun_11110', 'home_sigun_11140', 'home_sigun_11170', 'home_sigun_11200', 'home_sigun_11215', 'home_sigun_11230', 
            'home_sigun_11290', 'home_sigun_11305', 'home_sigun_11350', 'home_sigun_11380', 'home_sigun_11440', 'home_sigun_11545', 'home_sigun_11560', 'home_sigun_11620', 'home_sigun_26110', 
            'home_sigun_26140', 'home_sigun_26170', 'home_sigun_26230', 'home_sigun_26260', 'home_sigun_26290', 'home_sigun_26320', 'home_sigun_26350', 'home_sigun_26380', 'home_sigun_26260',
            'home_sigun_26440', 'home_sigun_26470', 'home_sigun_26500', 'home_sigun_26710', 'home_sigun_27110', 'home_sigun_27140', 'home_sigun_27170', 'home_sigun_27200', 'home_sigun_27230',
            'home_sigun_27260', 'home_sigun_27290', 'home_sigun_27710', ...}


##### Setting Test data #####

# 데이터 로드

  test_df = pd.read_csv('your_path')


# 선별된 변수 리스트 저장

  res_var = list(var_set)


# 타겟 변수 식에 맞게 변환

  test_df['reg_target'] = test_df['ele_car_1_sum'] / (test_df['car_own_1_sum'] + test_df['car_own_2_sum'])

  
# 국내 차 보유 인구수와 수입 차 보유 인구수 모두 0 인 경우 결측값을 반환하므로 0.0 으로 대체

  test_df['reg_target'] = test_df['reg_target'].fillna(0.0)


# 분류 분석에 사용할 변수 생성 (0, 1)

  test_df['cls_target'] = (test_df['ele_car_1_sum'] >= 1).astype('int')


# 타겟 값 생성에 사용된 변수는 데이터 leakage 방지를 위해 제거

  columns_drop = ['ele_car_1_sum', 'car_own_1_sum', 'car_own_2_sum']

  test_df = test_dfdf.drop(columns = columns_drop)


# X, 분류 타겟 변수, 회귀 타겟 변수 지정

  X_test, y_test_cls, y_test_reg = test_dfdf[sorted(res_var)], test_df['cls_target'].to_numpy(), test_df['reg_target'].to_numpy()



##### MinMaxScaler #####

with open('scaler.pkl', 'rb') as f :
    scaler = pickle.load(f)

X_test = scaler.transform(X_test)



##### Test Model #####

  def test_model(X_test, cls_y, reg_y, seed_val) : 

      # 랜덤 요소 제어
      seed_everything(seed_val)

      # 모델 인자 정의
      input_size = X_test.shape[1]
      encoding_dim = 32
      num_classes = 2
      num_epochs = 50
      num_train_size = X_test.shape[0]


      X_tensor, y_tensor = torch.tensor(X_test, dtype = torch.float32), torch.tensor(cls_y, dtype = torch.float32)
      reg_y = torch.tensor(reg_y, dtype = torch.float32)


      loaded_model = AutoencoderClassifier(input_size, encoding_dim, num_classes)
      loaded_model.load_state_dict(torch.load('cls_model.pkl'))

      loaded_model.eval()


      _, class_outputs1 = cls_model(X_tensor)
      _, test_pred = class_outputs1.max(1)
  
      print('train_auc', roc_auc_score(train_pred, y_tensor.numpy())
  
  
      test_pos_ind = torch.where(test_pred == 1)[0]

      loaded_model2 = RegressionModel(input_size, 128, 32, 8)
      loaded_model2.load_state_dict(torch.load('reg_model.pkl'))

      loaded_model2.eval()


      pre_reg_test = torch.zeros(len(X_tensor), 1)
      pre_reg_test[test_pos_ind] = loaded_model2(X_tensor[test_pos_ind])

      print("Test_MSE: ", mean_squared_error(pre_reg_test.detach().numpy(), reg_y.numpy()))

      return pre_reg_test


test_res = test_model(X_test, y_test_cls, y_test_reg, seed_val = 11)





